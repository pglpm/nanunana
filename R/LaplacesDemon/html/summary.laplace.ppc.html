<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>R: Posterior Predictive Check Summary</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="R.css">
</head><body>

<table width="100%" summary="page for summary.laplace.ppc {LaplacesDemon}"><tr><td>summary.laplace.ppc {LaplacesDemon}</td><td align="right">R Documentation</td></tr></table>

<h2>Posterior Predictive Check Summary</h2>

<h3>Description</h3>


<p>This may be used to summarize either new, unobserved instances of
<i>y</i> (called <i>y[new]</i>) or
replicates of <i>y</i> (called
<i>y[rep]</i>). Either <i>y[new]</i> or
<i>y[rep]</i> is summarized, depending on
<code><a href="../../LaplacesDemon/html/predict.laplace.html">predict.laplace</a></code>.
</p>


<h3>Usage</h3>

<pre>## S3 method for class 'laplace.ppc'
summary(object, Categorical, Rows, Discrep,
     d, Quiet, ...)</pre>


<h3>Arguments</h3>


<table summary="R argblock">
<tr valign="top"><td><code>object</code></td>
<td>
<p>An object of class <code>laplace.ppc</code> is required.</p>
</td></tr>
<tr valign="top"><td><code>Categorical</code></td>
<td>
<p>Logical. If <code>TRUE</code>, then <code>y</code> and
<code>yhat</code> are considered to be categorical (such as y=0 or y=1),
rather than continuous.</p>
</td></tr>
<tr valign="top"><td><code>Rows</code></td>
<td>
<p>An optional vector of row numbers, for example
<code>c(1:10)</code>. All rows will be estimated, but only these rows will
appear in the summary.</p>
</td></tr>
<tr valign="top"><td><code>Discrep</code></td>
<td>
<p>A character string indicating a discrepancy
test. <code>Discrep</code> defaults to <code>NULL</code>. Valid character
strings when <code>y</code> is continuous are: <code>"Chi-Square"</code>,
<code>"Chi-Square2"</code>, <code>"Kurtosis"</code>, <code>"L-criterion"</code>,
<code>"MASE"</code>, <code>"MSE"</code>, <code>"PPL"</code>, <code>"Quadratic Loss"</code>,
<code>"Quadratic Utility"</code>, <code>"RMSE"</code>, <code>"Skewness"</code>,
<code>"max(yhat[i,]) &gt; max(y)"</code>, <code>"mean(yhat[i,]) &gt; mean(y)"</code>,
<code>"mean(yhat[i,] &gt; d)"</code>, <code>"mean(yhat[i,] &gt; mean(y))"</code>,
<code>"min(yhat[i,]) &lt; min(y)"</code>, <code>"round(yhat[i,]) = d"</code>, and
<code>"sd(yhat[i,]) &gt; sd(y)"</code>. Valid character strings when <code>y</code>
is categorical are: <code>"p(yhat[i,] != y[i])"</code>. Kurtosis and
skewness are not discrepancies, but are included here for convenience.</p>
</td></tr>
<tr valign="top"><td><code>d</code></td>
<td>
<p>This is an optional integer to be used with the
<code>Discrep</code> argument above, and it defaults to <code>d=0</code>.</p>
</td></tr>
<tr valign="top"><td><code>Quiet</code></td>
<td>
<p>This logical argument defaults to <code>FALSE</code> and will
print results to the console. When <code>TRUE</code>, results are not
printed.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Additional arguments are unused.</p>
</td></tr>
</table>


<h3>Details</h3>


<p>This function summarizes an object of class <code>laplace.ppc</code>, which
consists of posterior predictive checks on either
<i>y[new]</i> or <i>y[rep]</i>,
depending respectively on whether unobserved instances of
<i>y</i> or the model sample of <i>y</i> was
used in the <code><a href="../../LaplacesDemon/html/predict.laplace.html">predict.laplace</a></code> function. The deviance and
monitored variables are also summarized.
</p>
<p>The purpose of a posterior predictive check is to assess how well (or
poorly) the model fits the data, or to assess discrepancies between
the model and the data.
</p>
<p>When <i>y</i> is continuous and known, this function
estimates the predictive concordance between <i>y</i> and
<i>y[rep]</i> as per Gelfand (1996), and the
predictive quantile (PQ), which is for record-level outlier detection
used to calculate Gelfand's predictive concordance.
</p>
<p>When <i>y</i> is categorical and known, this function
estimates the record-level lift, which is
<code>p(yhat[i,] = y[i]) / [p(y = j) / n]</code>, or
the number of correctly predicted samples over the rate of that
category of <i>y</i> in vector <i>y</i>.
</p>
<p>A discrepancy measure is an approach to studying discrepancies between
the model and data (Gelman et al., 1996). Below is a list of
discrepancy measures, followed by a brief introduction to discrepancy
analysis:
</p>

<ul>
<li><p> The <code>"Chi-Square"</code> discrepancy measure is the chi-square
goodness-of-fit test that is recommended by Gelman. For each record
i=1:N, this returns (y[i] - E(y[i]))^2 / var(yhat[i,]).
</p>
</li>
<li><p> The <code>"Chi-Square2"</code> discrepancy measure returns the
following for each record: Pr(chisq.rep[i,] &gt; chisq.obs[i,]), where
chisq.obs[i,] &lt;- (y[i] - E(y[i]))^2 / E(y[i]), and chisq.rep[i,] &lt;-
(yhat[i,] - E(yhat[i,]))^2 / E(yhat[i,]), and the overall
discrepancy is the percent of records that were outside of the 95%
quantile-based probability interval (see <code><a href="../../LaplacesDemon/html/p.interval.html">p.interval</a></code>).
</p>
</li>
<li><p> The <code>"Kurtosis"</code> discrepancy measure returns the kurtosis
of <i>y[rep]</i> for each record, and the discrepancy
statistic is the mean for all records. This does not measure
discrepancies between the model and data, and is useful for finding
kurtotic replicate distributions.
</p>
</li>
<li><p> The <code>"L-criterion"</code> discrepancy measure of Laud and Ibrahim
(1995) provides the record-level combination of two components (see
below), and the discrepancy statistic is the sum, <code>L</code>, as well as
a calibration number, <code>S.L</code>. For more information on the
L-criterion, see the accompanying vignette entitled &quot;Bayesian
Inference&quot;.
</p>
</li>
<li><p> The <code>"MASE"</code> (Mean Absolute Scaled Error) is a
discrepancy measure for the accuracy of time-series forecasts,
estimated as <code>(|y - yhat|) / mean(abs(diff(y)))</code>. The discrepancy
statistic is the mean of the record-level values.
</p>
</li>
<li><p> The <code>"MSE"</code> (Mean Squared Error) discrepancy measure
provides the MSE for each record across all replicates, and the
discrepancy statistic is the mean of the record-level MSEs. MSE and
quadratic loss are identical.
</p>
</li>
<li><p> The <code>"PPL"</code> (Posterior Predictive Loss) discrepancy
measure of Gelfand and Ghosh (1998) provides the record-level
combination of two components: one involves the predictive variance
and the other includes the accuracy of the means of the predictive
distribution. The <code>d=0</code> argument applies the following weight to
the accuracy component, which is then added to the variance component:
<i>d/(d+1)</i>. For <i>y[new]</i>, use <i>d=0</i>. For
<i>y[rep]</i> and model comparison, <i>d</i> is
commonly set to 1, 10, or 100000. Larger values of <i>d</i> put more
stress on fit and downgrade the precision of the estimates.
</p>
</li>
<li><p> The <code>"Quadratic Loss"</code> discrepancy measure provides the
mean quadratic loss for each record across all replicates, and the
discrepancy statistic is the mean of the record-level mean quadratic
losses. Quadratic loss and MSE are identical, and quadratic loss is
the negative of quadratic utility.
</p>
</li>
<li><p> The <code>"Quadratic Utility"</code> discrepancy measure provides
the mean quadratic utility for each record across all replicates, and
the discrepancy statistic is the mean of the record-level mean
quadratic utilities. Quadratic utility is the negative of quadratic
loss.
</p>
</li>
<li><p> The <code>"RMSE"</code> (Root Mean Squared Error) discrepancy
measure provides the RMSE for each record across all replicates, and
the discrepancy statistic is the mean of the record-level RMSEs.
</p>
</li>
<li><p> The <code>"Skewness"</code> discrepancy measure returns the skewness
of <i>y[rep]</i> for each record, and the discrepancy
statistic is the mean for all records. This does not measure
discrepancies between the model and data, and is useful for finding
skewed replicate distributions.
</p>
</li>
<li><p> The <code>"max(yhat[i,]) &gt; max(y)"</code> discrepancy measure
returns a record-level indicator when a record's maximum
<i>y[rep][i]</i> exceeds the maximum of
<i>y</i>. The discrepancy statistic is the mean of the
record-level indicators, reporting the proportion of records with
replications that exceed the maximum of <i>y</i>.
</p>
</li>
<li><p> The <code>"mean(yhat[i,]) &gt; mean(y)"</code> discrepancy measure
returns a record-level indicator when the mean of a record's
<i>y[rep][i]</i> is greater than the mean of
<i>y</i>. The discrepancy statistic is the mean of the
record-level indicators, reporting the proportion of records with
mean replications that exceed the mean of <i>y</i>.
</p>
</li>
<li><p> The <code>"mean(yhat[i,] &gt; d)"</code> discrepancy measure returns a
record-level proportion of <i>y[rep][i]</i> that
exceeds a specified value, <code>d</code>. The discrepancy statistic is the
mean of the record-level proportions.
</p>
</li>
<li><p> The <code>"mean(yhat[i,] &gt; mean(y))"</code> discrepancy measure
returns a record-level proportion of
<i>y[rep][i]</i> that exceeds the mean of
<i>y</i>. The discrepancy statistic is the mean of the
record-level proportions.
</p>
</li>
<li><p> The <code>"min(yhat[i,]) &lt; min(y)"</code> discrepancy measure
returns a record-level indicator when a record's minimum
<i>y[rep][i]</i> is less than the minimum of
<i>y</i>. The discrepancy statistic is the mean of the
record-level indicators, reporting the proportion of records with
replications less than the minimum of <i>y</i>.
</p>
</li>
<li><p> The <code>"round(yhat[i,]) = d"</code> discrepancy measure returns a
record-level proportion of <i>y[rep][i]</i> that,
when rounded, is equal to a specified discrete value, <code>d</code>. The
discrepancy statistic is the mean of the record-level proportions.
</p>
</li>
<li><p> The <code>"sd(yhat[i,]) &gt; sd(y)"</code> discrepancy measure returns a
record-level indicator when the standard deviation of replicates is
larger than the standard deviation of all of <i>y</i>. The
discrepancy statistic is the mean of the record-level indicators,
reporting the proportion of records with larger standard deviations
than <i>y</i>.
</p>
</li>
<li><p> The <code>"p(yhat[i,] != y[i])"</code> discrepancy measure returns
the record-level probability that <i>y[rep][i]</i>
is not equal to <i>y</i>. This is valid when
<i>y</i> is categorical and <code>yhat</code> is the predicted
category. The probability is the proportion of replicates.
</p>
</li></ul>

<p>After observing a discrepancy statistic, the user attempts to improve
the model by revising the model to account for discrepancies between
data and the current model. This approach to model revision relies on
an analysis of the discrepancy statistic. Given a discrepancy measure
that is based on model fit, such as the L-criterion, the user may
correlate the record-level discrepancy statistics with the dependent
variable, independent variables, and interactions of independent
variables. The discrepancy statistic should not correlate with the
dependent and independent variables. Interaction variables may be
useful for exploring new relationships that are not in the current
model. Alternatively, a decision tree may be applied to the
record-level discrepancy statistics, given the independent variables,
in an effort to find relationships in the data that may be helpful
in the model. Model revision may involve the addition of a finite
mixture component to account for outliers in discrepancy, or
specifying the model with a distribution that is more robust to
outliers. There are too many suggestions to include here, and
discrepancy analysis varies by model.
</p>


<h3>Value</h3>


<p>This function returns a list with the following components:
</p>
<table summary="R valueblock">
<tr valign="top"><td><code>BPIC</code></td>
<td>
<p>The Bayesian Predictive Information Criterion (BPIC) was
introduced by Ando (2007). BPIC is a variation of the Deviance
Information Criterion (DIC) that has been modified for predictive
distributions. For more information on DIC (Spiegelhalter
et al., 2002), see the accompanying vignette entitled &quot;Bayesian
Inference&quot;. <i>BPIC = Dbar + 2pD</i>. The goal is to minimize BPIC.</p>
</td></tr>
<tr valign="top"><td><code>Concordance</code></td>
<td>
<p>This is the percentage of the records of y that are
within the 95% quantile-based probability interval (see
<code><a href="../../LaplacesDemon/html/p.interval.html">p.interval</a></code>) of <i>y[rep]</i>.
Gelfand's suggested goal is to achieve 95% predictive concordance.
Lower percentages indicate too many outliers and a poor fit of the
model to the data, and higher percentages may suggest overfitting.
Concordance occurs only when <i>y</i> is continuous.</p>
</td></tr>
<tr valign="top"><td><code>Mean Lift</code></td>
<td>
<p>This is the mean of the record-level lifts, and
occurs only when <i>y</i> is specified as categorical
with <code>Categorical=TRUE</code>.</p>
</td></tr>
<tr valign="top"><td><code>Discrepancy.Statistic</code></td>
<td>
<p>This is only reported if the
<code>Discrep</code> argument receives a valid discrepancy measure as
listed above. The <code>Discrep</code> applies to each record of
<i>y</i>, and the <code>Discrepancy.Statistic</code> reports
the results of the discrepancy measure on the entire data set. For
example, if <code>Discrep="min(yhat[i,]) &lt; min(y)"</code>, then the
overall result is the proportion of records in which the minimum
sample of yhat was less than the overall minimum
<i>y</i>. This is <code>Pr(min(yhat[i,]) &lt; min(y) | y,
      Theta)</code>, where <code>Theta</code> is the parameter set.</p>
</td></tr>
<tr valign="top"><td><code>L-criterion</code></td>
<td>
<p>The L-criterion (Laud and Ibrahim, 1995) was
developed for model and variable selection. It is a sum of two
components: one involves the predictive variance and the other
includes the accuracy of the means of the predictive
distribution. The L-criterion measures model performance with a
combination of how close its predictions are to the observed data
and variability of the predictions. Better models have smaller
values of <code>L</code>. <code>L</code> is measured in the same units as
the response variable, and measures how close the data vector
<i>y</i> is to the predictive distribution. In addition
to the value of <code>L</code>, there is a value for <code>S.L</code>, which is
the calibration number of <code>L</code>, and is useful in determining how
much of a decrease is necessary between models to be noteworthy.</p>
</td></tr>
<tr valign="top"><td><code>Monitor</code></td>
<td>
<p>This is a <i>N x 5</i> matrix, where <i>N</i>
is the number of monitored variables and there are 5 columns, as
follows: Mean, SD, LB (the 2.5% quantile), Median, and UB (the
97.5% quantile).</p>
</td></tr>
<tr valign="top"><td><code>Summary</code></td>
<td>
<p>When <i>y</i> is continuous, this is a
<i>N x 8</i> matrix, where <i>N</i> is the number of
records of <i>y</i> and there are 8 columns, as follows:
y, Mean, SD, LB (the 2.5% quantile), Median, UB (the 97.5%
quantile), PQ (the predictive quantile, which is
<i>Pr(y[rep] &gt;= y)</i>), and
Test, which shows the record-level result of a test, if
specified. When <i>y</i> is categorical, this matrix has
a number of columns equal to the number of categories of
<i>y</i> plus 3, also including <code>y</code>, <code>Lift</code>,
and <code>Discrep</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Byron Hall <a href="mailto:statisticat@gmail.com">statisticat@gmail.com</a></p>


<h3>References</h3>


<p>Ando, T. (2007). &quot;Bayesian Predictive Information Criterion for
the Evaluation of Hierarchical Bayesian and Empirical Bayes Models&quot;.
Biometrika, 94 (2), p. 443&ndash;458.
</p>
<p>Gelfand, A. (1996). &quot;Model Determination Using Sampling Based
Methods&quot;. In Gilks, W., Richardson, S., Spiegehalter, D., Chapter 9 in
Markov Chain Monte Carlo in Practice. Chapman \&amp; Hall: Boca Raton, FL.
</p>
<p>Gelfand, A. and Ghosh, S. (1998). &quot;Model Choice: A Minimum Posterior
Predictive Loss Approach&quot;. Biometrika, 85, p. 1&ndash;11.
</p>
<p>Gelman, A., Meng, X.L., and Stern H. (1996). &quot;Posterior Predictive
Assessment of Model Fitness via Realized Discrepancies&quot;. Statistica
Sinica, 6, p. 733&ndash;807.
</p>
<p>Hall, B. (2012), &quot;Laplace's Demon&quot;, STATISTICAT, LLC.
URL=<a href="http://www.statisticat.com/laplacesdemon.html">http://www.statisticat.com/laplacesdemon.html</a>
</p>
<p>Laud, P.W. and Ibrahim, J.G. (1995). &quot;Predictive Model Selection&quot;.
Journal of the Royal Statistical Society, B 57, p. 247&ndash;262.
</p>
<p>Spiegelhalter, D.J., Best, N.G., Carlin, B.P., and van der Linde, A.
(2002). &quot;Bayesian Measures of Model Complexity and Fit (with
Discussion)&quot;. Journal of the Royal Statistical Society, B 64,
p. 583&ndash;639.
</p>


<h3>See Also</h3>


<p><code><a href="../../LaplacesDemon/html/LaplaceApproximation.html">LaplaceApproximation</a></code>,
<code><a href="../../LaplacesDemon/html/predict.laplace.html">predict.laplace</a></code>, and
<code><a href="../../LaplacesDemon/html/p.interval.html">p.interval</a></code>.
</p>


<h3>Examples</h3>

<pre>### See the LaplaceApproximation function for an example.</pre>

<hr><div align="center">[Package <em>LaplacesDemon</em> version 12.08.06 <a href="00Index.html">Index</a>]</div>
</body></html>