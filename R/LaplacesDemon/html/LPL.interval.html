<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>R: Lowest Posterior Loss Interval</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="R.css">
</head><body>

<table width="100%" summary="page for LPL.interval {LaplacesDemon}"><tr><td>LPL.interval {LaplacesDemon}</td><td align="right">R Documentation</td></tr></table>

<h2>Lowest Posterior Loss Interval</h2>

<h3>Description</h3>


<p>This function returns the Lowest Posterior Loss (LPL) interval for one
parameter, given samples from the density of its prior distribution
and samples of the posterior distribution.
</p>


<h3>Usage</h3>

<pre>
LPL.interval(Prior, Posterior, prob=0.95, plot=FALSE, PDF=FALSE)
</pre>


<h3>Arguments</h3>


<table summary="R argblock">
<tr valign="top"><td><code>Prior</code></td>
<td>
<p>This is a vector of samples of the prior density.</p>
</td></tr>
<tr valign="top"><td><code>Posterior</code></td>
<td>
<p>This is a vector of posterior samples.</p>
</td></tr>
<tr valign="top"><td><code>prob</code></td>
<td>
<p>This is a numeric scalar in the interval (0,1) giving the
Lowest Posterior Loss (LPL) interval, and defaults to 0.95,
representing a 95% LPL interval.</p>
</td></tr>
<tr valign="top"><td><code>plot</code></td>
<td>
<p>Logical. When <code>plot=TRUE</code>, two plots are
produced. The top plot shows the expected posterior loss. The LPL
region is shaded black, and the area outside the region is gray. The
bottom plot shows LPL interval of <i>theta</i> on the kernel
density of <i>theta</i>. Again, the LPL region is shaded
black, and the outside area is gray. A vertical, red, dotted line is
added at zero for both plots. The <code>plot</code> argument defaults to
<code>FALSE</code>. The plot treats the distribution as if it were
unimodal; disjoint regions are not estimated here. If multimodality
should result in disjoint regions, then consider using HPD intervals
in the <code><a href="../../LaplacesDemon/html/p.interval.html">p.interval</a></code> function.</p>
</td></tr>
<tr valign="top"><td><code>PDF</code></td>
<td>
<p>Logical. When <code>PDF=TRUE</code>, and only when
<code>plot=TRUE</code>, plots are saved as a .pdf file in the working
directory.</p>
</td></tr>
</table>


<h3>Details</h3>


<p>The Lowest Posterior Loss (LPL) interval (Bernardo, 2005), or LPLI, is
a probability interval based on intrinsic discrepancy loss between
prior and posterior distributions. The expected posterior loss
is the loss associated with using a particular value
<i>theta[i] in theta</i> of the parameter as the
unknown true value of <i>theta</i> (Bernardo, 2005). Parameter
values with smaller expected posterior loss should always be
preferred. The LPL interval includes a region in which all parameter
values have smaller expected posterior loss than those outside the
region.
</p>
<p>Although any loss function could be used, the loss function should be
invariant under reparameterization. Any intrinsic loss function is
invariant under reparameterization, but not necessarily invariant
under one-to-one transformations of data <i>x</i>. When a
loss function is also invariant under one-to-one transformations, it
is usually also invariant when reduced to a sufficient statistic. Only
an intrinsic loss function that is invariant when reduced to a
sufficient statistic should be considered.
</p>
<p>The intrinsic discrepancy loss is easily a superior loss function to
the overused quadratic loss function, and is more appropriate than
other popular measures, such as Hellinger distance, Kullback-Leibler
divergence (<code><a href="../../LaplacesDemon/html/KLD.html">KLD</a></code>), and Jeffreys logarithmic
divergence. The intrinsic discrepancy loss is also an
information-theory related divergence measure. Intrinsic discrepancy
loss is a symmetric, non-negative loss function, and is a continuous,
convex function. Intrinsic discrepancy loss was introduced
by Bernardo and Rueda (2002) in a different context: hypothesis
testing. Formally, it is:
</p>
<p align="center"><i>delta f(p[2],p[1]) = min[kappa(p[2] | p[1]), kappa(p[1] | p[2])]</i></p>

<p>where <i>delta</i> is the discrepancy, <i>kappa</i> is
the <code><a href="../../LaplacesDemon/html/KLD.html">KLD</a></code>, and <i>p[1]</i> and <i>p[2]</i> are the
probability distributions. The intrinsic discrepancy loss is the loss
function, and the expected posterior loss is the mean of the directed
divergences.
</p>
<p>The LPL interval is also called an intrinsic credible interval or
intrinsic probability interval, and the area inside the interval is
often called an intrinsic credible region or intrinsic probability
region.
</p>
<p>In practice, whether a reference prior or weakly informative prior
(WIP) is used, the LPL interval is usually very close to the HPD
interval, though the posterior losses may be noticeably different. If
LPL used a zero-one loss function, then the HPD interval would be
produced. An advantage of the LPL interval over HPD interval (see
<code><a href="../../LaplacesDemon/html/p.interval.html">p.interval</a></code>) is that the LPL interval is invariant to
reparameterization. This is due to the invariant reparameterization
property of reference priors. The quantile-based probability interval
is also invariant to reparameterization. The LPL interval enjoys the
same advantage as the HPD interval does over the quantile-based
probability interval: it does not produce equal tails when
inappropriate.
</p>
<p>Compared with probability intervals, the LPL interval is slightly less
convenient to calculate. Although the prior distribution is specified
within the <code>Model</code> specification function, the user must specify
it for the <code>LPL.interval</code> function as well.
</p>


<h3>Value</h3>


<p>A matrix is returned with one row and two columns. The row represents
the parameter and the column names are <code>"Lower"</code> and
<code>"Upper"</code>. The elements of the matrix are the lower and upper
bounds of the LPL interval.
</p>


<h3>References</h3>


<p>Bernardo, J.M. (2005). &quot;Intrinsic Credible Regions: An Objective
Bayesian Approach to Interval Estimation&quot;. Sociedad de Estadistica e
Investigacion Operativa, 14, 2, p. 317&ndash;384.
</p>
<p>Bernardo, J.M. and Rueda, R. (2002). &quot;Bayesian Hypothesis Testing: A
Reference Approach&quot;. International Statistical Review, 70, p. 351&ndash;372.
</p>
<p>Hall, B. (2012). &quot;Laplace's Demon&quot;, STATISTICAT, LLC.
URL=<a href="http://www.statisticat.com/laplacesdemon.html">http://www.statisticat.com/laplacesdemon.html</a>
</p>


<h3>See Also</h3>


<p><code><a href="../../LaplacesDemon/html/KLD.html">KLD</a></code>,
<code><a href="../../LaplacesDemon/html/p.interval.html">p.interval</a></code>,
<code><a href="../../LaplacesDemon/html/LaplacesDemon.html">LaplacesDemon</a></code>, and
<code><a href="../../LaplacesDemon/html/PMC.html">PMC</a></code>.</p>


<h3>Examples</h3>

<pre>
#Although LPL is intended to be applied to output from LaplacesDemon or
#PMC, here is an example in which p(theta) ~ N(0,100), and
#p(theta | y) ~ N(1,10), given 1000 samples.
theta &lt;- rnorm(1000,1,10)
LPL.interval(Prior=dnorm(theta,0,100^2), Posterior=theta, prob=0.95,
  plot=TRUE)
#A more practical example follows, but it assumes a model has been
#updated with LaplacesDemon or PMC, the output object is called Fit, and
#that the prior for the third parameter is normally distributed with
#mean 0 and variance 100: 
#temp &lt;- Fit$Posterior2[,3]
#names(temp) &lt;- colnames(Fit$Posterior2)[3]
#LPL.interval(Prior=dnorm(temp,0,100^2), Posterior=temp, prob=0.95,
#     plot=TRUE, PDF=FALSE)
</pre>

<hr><div align="center">[Package <em>LaplacesDemon</em> version 12.08.06 <a href="00Index.html">Index</a>]</div>
</body></html>