<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>R: Variable Importance</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="R.css">
</head><body>

<table width="100%" summary="page for Importance {LaplacesDemon}"><tr><td>Importance {LaplacesDemon}</td><td align="right">R Documentation</td></tr></table>

<h2>Variable Importance</h2>

<h3>Description</h3>


<p>The <code>Importance</code> function considers variable importance (or
predictor importance) to be the effect that the variable has on
replicates <i>y^rep</i> (or
<i>Y^rep</i>) when the variable is removed from the
model by setting it equal to zero. Here, variable importance is
considered in terms of the comparison of posterior predictive
checks. This may be considered to be a form of sensitivity analysis,
and can be useful for model revision, variable selection, and model
interpretation.
</p>
<p>Currently, this function only tests the variable importance of design
matrix <i>X</i>.
</p>


<h3>Usage</h3>

<pre>
Importance(object, Model, Data, Categorical=FALSE, Discrep, d=0)
</pre>


<h3>Arguments</h3>


<table summary="R argblock">
<tr valign="top"><td><code>object</code></td>
<td>
<p>An object of class <code>demonoid</code>, <code>laplace</code>, or
<code>pmc</code> is required.</p>
</td></tr>
<tr valign="top"><td><code>Model</code></td>
<td>
<p>The model specification function is required.</p>
</td></tr>
<tr valign="top"><td><code>Data</code></td>
<td>
<p>A data set in a list is required. The dependent variable
is required to be named either <code>y</code> or <code>Y</code>. The
<code>Importance</code> function will sequentially remove each column
vector in <code>X</code>, so <code>X</code> is required to be in data set
<code>Data</code>.</p>
</td></tr>
<tr valign="top"><td><code>Categorical</code></td>
<td>
<p>Logical. If <code>TRUE</code>, then <code>y</code> and
<code>yhat</code> are considered to be categorical (such as y=0 or y=1),
rather than continuous. This defaults to <code>FALSE</code>.</p>
</td></tr>
<tr valign="top"><td><code>Discrep</code></td>
<td>
<p>This optional argument allows a discrepancy statistic to
be included. For more information on discrepancy statistics, see
<code><a href="../../LaplacesDemon/html/summary.demonoid.ppc.html">summary.demonoid.ppc</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>d</code></td>
<td>
<p>This is an optional integer to be used with the
<code>Discrep</code> argument above, and it defaults to <code>d=0</code>. For
more information on discrepancy, see
<code><a href="../../LaplacesDemon/html/summary.demonoid.ppc.html">summary.demonoid.ppc</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variable importance is defined here as the impact of each
variable (predictor, or column vector) in design matrix
<i>X</i> on <i>y^rep</i> (or
<i>Y^rep</i>), when the variable is removed.
</p>
<p>First, the full model is predicted with the
<code><a href="../../LaplacesDemon/html/predict.demonoid.html">predict.demonoid</a></code>, or <code><a href="../../LaplacesDemon/html/predict.laplace.html">predict.laplace</a></code>, or
<code><a href="../../LaplacesDemon/html/predict.pmc.html">predict.pmc</a></code> function, and summarized with the
<code><a href="../../LaplacesDemon/html/summary.demonoid.ppc.html">summary.demonoid.ppc</a></code>, <code><a href="../../LaplacesDemon/html/summary.laplace.ppc.html">summary.laplace.ppc</a></code>,
or <code><a href="../../LaplacesDemon/html/summary.pmc.ppc.html">summary.pmc.ppc</a></code> function, respectively. The
results are stored in the first row of the output. Each successive
row in the output corresponds to the application of <code>predict</code> and
<code>summary</code> functions, but with each variable in design matrix
<i>X</i> being set to zero and effectively removed. The
results show the impact of sequentially removing each predictor.
</p>
<p>The criterion for variable importance may differ from model to
model. As a default, BPIC is recommended. The Bayesian Predictive
Information Criterion (BPIC) was introduced by Ando (2007). BPIC is a
variation of the Deviance Information Criterion (DIC) that has been
modified for predictive distributions. For more information on DIC
(Spiegelhalter et al., 2002), see the accompanying vignette entitled
&quot;Bayesian Inference&quot;. <i>BPIC = Dbar + 2pD</i>.
</p>
<p>With BPIC, variable importance has a positive relationship, such that
larger values indicate a more important variable, because removing
that variable resulted in a worse fit to the data. The best model
has the lowest BPIC.
</p>
<p>In a model in which the dependent variable is not categorical, it is
also recommended to consider the L-criterion (Laud and Ibrahim, 1995),
provided that sample size is small enough that it does not result in
<code>Inf</code>. For more information on the L-criterion, see the
accompanying vignette entitled &quot;Bayesian Inference&quot;.
</p>
<p>With the L-criterion, variable importance has a positive relationship, 
such that larger values indicate a more important variable, because
removing that variable resulted in a worse fit to the data. Ibrahim
(1995) recommended considering the model with the lowest
L-criterion, say as <i>L[1]</i>, and the model with the closest
L-criterion, say as <i>L[2]</i>, and creating a comparison score
as <i>phi = (L[2]-L[1])/S[L]</i>, where
<code>S.L</code> is from the <i>L[1]</i> model. If the comparison score,
<i>phi</i> is less than 2, then <i>L[2]</i> is within 2
standard deviations of <i>L[1]</i>, and is the recommended cut-off
for model choice.
</p>
<p>The <code>Importance</code> function may suggest that a model fits the data
better with a variable removed. In which case, the user may
choose to leave the variable in the model (perhaps the model is
misspecified without the variable), investigate and possibly
re-specify the relationship between the independent and dependent
variable(s), or remove the variable and update the model again.
</p>
<p>In contrast to variable importance, the <code><a href="../../LaplacesDemon/html/PosteriorChecks.html">PosteriorChecks</a></code>
function calculates parameter importance, which is the probability
that each parameter's marginal posterior distribution is greater than
zero, where an important parameter does not include zero in its
probability interval (see <code><a href="../../LaplacesDemon/html/p.interval.html">p.interval</a></code>). Parameter
importance and variable importance may disagree, and both should be
studied.
</p>
<p>The <code>Importance</code> function tends to indicate that a model fits the
data better when variables are removed that have parameters with
marginal posterior distributions that include 0 in the 95%
probability interval (variables associated with lower parameter
importance).
</p>
<p>Often, in complicated models, it is difficult to assess variable
importance by examining the marginal posterior distribution of the
associated parameter(s). Consider polynomial regression, in which each
variable may have multiple parameters.
</p>
<p>The information provided by the <code>Importance</code> function may be used
for model revision, or reporting the relative importance of variables.
</p>
<p>The <code><a href="../../LaplacesDemon/html/plot.importance.html">plot.importance</a></code> function is available to plot the
output of the <code>Importance</code> function according to BPIC, predictive
concordance (Gelfand, 1996), the selected discrepancy statistic
(Gelman et al., 1996), or the L-criterion.
</p>


<h3>Value</h3>


<p><code>Importance</code> returns an object of class <code>importance</code>, which
is a matrix with a number of rows equal to the number of columns in
design matrix <i>X</i> + 1 (including the full model), and
4 columns, which are BPIC, Concordance (or Mean.Lift if categorical),
Discrep, and L-criterion. Each row represents a model with a predictor
in <i>X</i> removed (except for the first row, which is the
full model), and the resulting posterior predictive checks. For
non-categorical dependent variables, an attribute is returned with the
object, and the attribute is a vector of <code>S.L</code>, the calibration
number of the L-criterion.
</p>


<h3>Author(s)</h3>

<p>Byron Hall <a href="mailto:statisticat@gmail.com">statisticat@gmail.com</a></p>


<h3>References</h3>


<p>Ando, T. (2007). &quot;Bayesian Predictive Information Criterion for
the Evaluation of Hierarchical Bayesian and Empirical Bayes Models&quot;.
Biometrika, 94 (2), p. 443&ndash;458.
</p>
<p>Gelfand, A. (1996). &quot;Model Determination Using Sampling Based
Methods&quot;. In Gilks, W., Richardson, S., Spiegehalter, D., Chapter 9 in
Markov Chain Monte Carlo in Practice. Chapman \&amp; Hall: Boca Raton, FL.
</p>
<p>Hall, B. (2012). &quot;Laplace's Demon&quot;, STATISTICAT, LLC.
URL=<a href="http://www.statisticat.com/laplacesdemon.html">http://www.statisticat.com/laplacesdemon.html</a>
</p>
<p>Laud, P.W. and Ibrahim, J.G. (1995). &quot;Predictive Model
Selection&quot;. Journal of the Royal Statistical Society, B 57,
p. 247&ndash;262.
</p>
<p>Spiegelhalter, D.J., Best, N.G., Carlin, B.P., and van der Linde, A.
(2002). &quot;Bayesian Measures of Model Complexity and Fit (with
Discussion)&quot;. Journal of the Royal Statistical Society, B 64,
p. 583&ndash;639.
</p>


<h3>See Also</h3>


<p><code><a href="../../LaplacesDemon/html/is.importance.html">is.importance</a></code>,
<code><a href="../../LaplacesDemon/html/LaplaceApproximation.html">LaplaceApproximation</a></code>,
<code><a href="../../LaplacesDemon/html/LaplacesDemon.html">LaplacesDemon</a></code>,
<code><a href="../../LaplacesDemon/html/PMC.html">PMC</a></code>,
<code><a href="../../LaplacesDemon/html/plot.importance.html">plot.importance</a></code>,
<code><a href="../../LaplacesDemon/html/PosteriorChecks.html">PosteriorChecks</a></code>,
<code><a href="../../LaplacesDemon/html/p.interval.html">p.interval</a></code>,
<code><a href="../../LaplacesDemon/html/predict.demonoid.html">predict.demonoid</a></code>,
<code><a href="../../LaplacesDemon/html/predict.laplace.html">predict.laplace</a></code>,
<code><a href="../../LaplacesDemon/html/predict.pmc.html">predict.pmc</a></code>,
<code><a href="../../LaplacesDemon/html/summary.demonoid.ppc.html">summary.demonoid.ppc</a></code>,
<code><a href="../../LaplacesDemon/html/summary.laplace.ppc.html">summary.laplace.ppc</a></code>, and
<code><a href="../../LaplacesDemon/html/summary.pmc.ppc.html">summary.pmc.ppc</a></code>.
</p>


<h3>Examples</h3>

<pre>
#First, update the model with the LaplacesDemon function, such as
#the example with linear regression, creating an object called Fit.
#Then
#Importance(Fit, Model, MyData, Discrep="Chi-Square")
</pre>

<hr><div align="center">[Package <em>LaplacesDemon</em> version 12.08.06 <a href="00Index.html">Index</a>]</div>
</body></html>